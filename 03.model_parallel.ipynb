{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c51943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21c642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21c642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['pad_token_id']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bb181cf9974680b766befa20a1ab09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"baffo32/decapoda-research-llama-7B-hf\",\n",
    "    quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1475730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, \t cuda:0 \t torch.float16\n",
      "1, \t cuda:0 \t torch.int8\n",
      "2, \t cuda:0 \t torch.int8\n",
      "3, \t cuda:0 \t torch.int8\n",
      "4, \t cuda:0 \t torch.int8\n",
      "5, \t cuda:0 \t torch.int8\n",
      "6, \t cuda:0 \t torch.int8\n",
      "7, \t cuda:0 \t torch.int8\n",
      "8, \t cuda:0 \t torch.float16\n",
      "9, \t cuda:0 \t torch.float16\n",
      "10, \t cuda:0 \t torch.int8\n",
      "11, \t cuda:0 \t torch.int8\n",
      "12, \t cuda:0 \t torch.int8\n",
      "13, \t cuda:0 \t torch.int8\n",
      "14, \t cuda:0 \t torch.int8\n",
      "15, \t cuda:0 \t torch.int8\n",
      "16, \t cuda:0 \t torch.int8\n",
      "17, \t cuda:0 \t torch.float16\n",
      "18, \t cuda:0 \t torch.float16\n",
      "19, \t cuda:0 \t torch.int8\n",
      "20, \t cuda:0 \t torch.int8\n",
      "21, \t cuda:0 \t torch.int8\n",
      "22, \t cuda:0 \t torch.int8\n",
      "23, \t cuda:0 \t torch.int8\n",
      "24, \t cuda:0 \t torch.int8\n",
      "25, \t cuda:0 \t torch.int8\n",
      "26, \t cuda:0 \t torch.float16\n",
      "27, \t cuda:0 \t torch.float16\n",
      "28, \t cuda:0 \t torch.int8\n",
      "29, \t cuda:0 \t torch.int8\n",
      "30, \t cuda:0 \t torch.int8\n",
      "31, \t cuda:0 \t torch.int8\n",
      "32, \t cuda:0 \t torch.int8\n",
      "33, \t cuda:0 \t torch.int8\n",
      "34, \t cuda:0 \t torch.int8\n",
      "35, \t cuda:0 \t torch.float16\n",
      "36, \t cuda:0 \t torch.float16\n",
      "37, \t cuda:0 \t torch.int8\n",
      "38, \t cuda:0 \t torch.int8\n",
      "39, \t cuda:0 \t torch.int8\n",
      "40, \t cuda:0 \t torch.int8\n",
      "41, \t cuda:0 \t torch.int8\n",
      "42, \t cuda:0 \t torch.int8\n",
      "43, \t cuda:0 \t torch.int8\n",
      "44, \t cuda:0 \t torch.float16\n",
      "45, \t cuda:0 \t torch.float16\n",
      "46, \t cuda:0 \t torch.int8\n",
      "47, \t cuda:0 \t torch.int8\n",
      "48, \t cuda:0 \t torch.int8\n",
      "49, \t cuda:0 \t torch.int8\n",
      "50, \t cuda:0 \t torch.int8\n",
      "51, \t cuda:0 \t torch.int8\n",
      "52, \t cuda:0 \t torch.int8\n",
      "53, \t cuda:0 \t torch.float16\n",
      "54, \t cuda:0 \t torch.float16\n",
      "55, \t cuda:1 \t torch.int8\n",
      "56, \t cuda:1 \t torch.int8\n",
      "57, \t cuda:1 \t torch.int8\n",
      "58, \t cuda:1 \t torch.int8\n",
      "59, \t cuda:1 \t torch.int8\n",
      "60, \t cuda:1 \t torch.int8\n",
      "61, \t cuda:1 \t torch.int8\n",
      "62, \t cuda:1 \t torch.float16\n",
      "63, \t cuda:1 \t torch.float16\n",
      "64, \t cuda:1 \t torch.int8\n",
      "65, \t cuda:1 \t torch.int8\n",
      "66, \t cuda:1 \t torch.int8\n",
      "67, \t cuda:1 \t torch.int8\n",
      "68, \t cuda:1 \t torch.int8\n",
      "69, \t cuda:1 \t torch.int8\n",
      "70, \t cuda:1 \t torch.int8\n",
      "71, \t cuda:1 \t torch.float16\n",
      "72, \t cuda:1 \t torch.float16\n",
      "73, \t cuda:1 \t torch.int8\n",
      "74, \t cuda:1 \t torch.int8\n",
      "75, \t cuda:1 \t torch.int8\n",
      "76, \t cuda:1 \t torch.int8\n",
      "77, \t cuda:1 \t torch.int8\n",
      "78, \t cuda:1 \t torch.int8\n",
      "79, \t cuda:1 \t torch.int8\n",
      "80, \t cuda:1 \t torch.float16\n",
      "81, \t cuda:1 \t torch.float16\n",
      "82, \t cuda:1 \t torch.int8\n",
      "83, \t cuda:1 \t torch.int8\n",
      "84, \t cuda:1 \t torch.int8\n",
      "85, \t cuda:1 \t torch.int8\n",
      "86, \t cuda:1 \t torch.int8\n",
      "87, \t cuda:1 \t torch.int8\n",
      "88, \t cuda:1 \t torch.int8\n",
      "89, \t cuda:1 \t torch.float16\n",
      "90, \t cuda:1 \t torch.float16\n",
      "91, \t cuda:1 \t torch.int8\n",
      "92, \t cuda:1 \t torch.int8\n",
      "93, \t cuda:1 \t torch.int8\n",
      "94, \t cuda:1 \t torch.int8\n",
      "95, \t cuda:1 \t torch.int8\n",
      "96, \t cuda:1 \t torch.int8\n",
      "97, \t cuda:1 \t torch.int8\n",
      "98, \t cuda:1 \t torch.float16\n",
      "99, \t cuda:1 \t torch.float16\n",
      "100, \t cuda:1 \t torch.int8\n",
      "101, \t cuda:1 \t torch.int8\n",
      "102, \t cuda:1 \t torch.int8\n",
      "103, \t cuda:1 \t torch.int8\n",
      "104, \t cuda:1 \t torch.int8\n",
      "105, \t cuda:1 \t torch.int8\n",
      "106, \t cuda:1 \t torch.int8\n",
      "107, \t cuda:1 \t torch.float16\n",
      "108, \t cuda:1 \t torch.float16\n",
      "109, \t cuda:1 \t torch.int8\n",
      "110, \t cuda:1 \t torch.int8\n",
      "111, \t cuda:1 \t torch.int8\n",
      "112, \t cuda:1 \t torch.int8\n",
      "113, \t cuda:1 \t torch.int8\n",
      "114, \t cuda:1 \t torch.int8\n",
      "115, \t cuda:1 \t torch.int8\n",
      "116, \t cuda:1 \t torch.float16\n",
      "117, \t cuda:1 \t torch.float16\n",
      "118, \t cuda:1 \t torch.int8\n",
      "119, \t cuda:1 \t torch.int8\n",
      "120, \t cuda:1 \t torch.int8\n",
      "121, \t cuda:1 \t torch.int8\n",
      "122, \t cuda:1 \t torch.int8\n",
      "123, \t cuda:1 \t torch.int8\n",
      "124, \t cuda:1 \t torch.int8\n",
      "125, \t cuda:1 \t torch.float16\n",
      "126, \t cuda:1 \t torch.float16\n",
      "127, \t cuda:2 \t torch.int8\n",
      "128, \t cuda:2 \t torch.int8\n",
      "129, \t cuda:2 \t torch.int8\n",
      "130, \t cuda:2 \t torch.int8\n",
      "131, \t cuda:2 \t torch.int8\n",
      "132, \t cuda:2 \t torch.int8\n",
      "133, \t cuda:2 \t torch.int8\n",
      "134, \t cuda:2 \t torch.float16\n",
      "135, \t cuda:2 \t torch.float16\n",
      "136, \t cuda:2 \t torch.int8\n",
      "137, \t cuda:2 \t torch.int8\n",
      "138, \t cuda:2 \t torch.int8\n",
      "139, \t cuda:2 \t torch.int8\n",
      "140, \t cuda:2 \t torch.int8\n",
      "141, \t cuda:2 \t torch.int8\n",
      "142, \t cuda:2 \t torch.int8\n",
      "143, \t cuda:2 \t torch.float16\n",
      "144, \t cuda:2 \t torch.float16\n",
      "145, \t cuda:2 \t torch.int8\n",
      "146, \t cuda:2 \t torch.int8\n",
      "147, \t cuda:2 \t torch.int8\n",
      "148, \t cuda:2 \t torch.int8\n",
      "149, \t cuda:2 \t torch.int8\n",
      "150, \t cuda:2 \t torch.int8\n",
      "151, \t cuda:2 \t torch.int8\n",
      "152, \t cuda:2 \t torch.float16\n",
      "153, \t cuda:2 \t torch.float16\n",
      "154, \t cuda:2 \t torch.int8\n",
      "155, \t cuda:2 \t torch.int8\n",
      "156, \t cuda:2 \t torch.int8\n",
      "157, \t cuda:2 \t torch.int8\n",
      "158, \t cuda:2 \t torch.int8\n",
      "159, \t cuda:2 \t torch.int8\n",
      "160, \t cuda:2 \t torch.int8\n",
      "161, \t cuda:2 \t torch.float16\n",
      "162, \t cuda:2 \t torch.float16\n",
      "163, \t cuda:2 \t torch.int8\n",
      "164, \t cuda:2 \t torch.int8\n",
      "165, \t cuda:2 \t torch.int8\n",
      "166, \t cuda:2 \t torch.int8\n",
      "167, \t cuda:2 \t torch.int8\n",
      "168, \t cuda:2 \t torch.int8\n",
      "169, \t cuda:2 \t torch.int8\n",
      "170, \t cuda:2 \t torch.float16\n",
      "171, \t cuda:2 \t torch.float16\n",
      "172, \t cuda:2 \t torch.int8\n",
      "173, \t cuda:2 \t torch.int8\n",
      "174, \t cuda:2 \t torch.int8\n",
      "175, \t cuda:2 \t torch.int8\n",
      "176, \t cuda:2 \t torch.int8\n",
      "177, \t cuda:2 \t torch.int8\n",
      "178, \t cuda:2 \t torch.int8\n",
      "179, \t cuda:2 \t torch.float16\n",
      "180, \t cuda:2 \t torch.float16\n",
      "181, \t cuda:2 \t torch.int8\n",
      "182, \t cuda:2 \t torch.int8\n",
      "183, \t cuda:2 \t torch.int8\n",
      "184, \t cuda:2 \t torch.int8\n",
      "185, \t cuda:2 \t torch.int8\n",
      "186, \t cuda:2 \t torch.int8\n",
      "187, \t cuda:2 \t torch.int8\n",
      "188, \t cuda:2 \t torch.float16\n",
      "189, \t cuda:2 \t torch.float16\n",
      "190, \t cuda:2 \t torch.int8\n",
      "191, \t cuda:2 \t torch.int8\n",
      "192, \t cuda:2 \t torch.int8\n",
      "193, \t cuda:2 \t torch.int8\n",
      "194, \t cuda:2 \t torch.int8\n",
      "195, \t cuda:2 \t torch.int8\n",
      "196, \t cuda:2 \t torch.int8\n",
      "197, \t cuda:2 \t torch.float16\n",
      "198, \t cuda:2 \t torch.float16\n",
      "199, \t cuda:3 \t torch.int8\n",
      "200, \t cuda:3 \t torch.int8\n",
      "201, \t cuda:3 \t torch.int8\n",
      "202, \t cuda:3 \t torch.int8\n",
      "203, \t cuda:3 \t torch.int8\n",
      "204, \t cuda:3 \t torch.int8\n",
      "205, \t cuda:3 \t torch.int8\n",
      "206, \t cuda:3 \t torch.float16\n",
      "207, \t cuda:3 \t torch.float16\n",
      "208, \t cuda:3 \t torch.int8\n",
      "209, \t cuda:3 \t torch.int8\n",
      "210, \t cuda:3 \t torch.int8\n",
      "211, \t cuda:3 \t torch.int8\n",
      "212, \t cuda:3 \t torch.int8\n",
      "213, \t cuda:3 \t torch.int8\n",
      "214, \t cuda:3 \t torch.int8\n",
      "215, \t cuda:3 \t torch.float16\n",
      "216, \t cuda:3 \t torch.float16\n",
      "217, \t cuda:3 \t torch.int8\n",
      "218, \t cuda:3 \t torch.int8\n",
      "219, \t cuda:3 \t torch.int8\n",
      "220, \t cuda:3 \t torch.int8\n",
      "221, \t cuda:3 \t torch.int8\n",
      "222, \t cuda:3 \t torch.int8\n",
      "223, \t cuda:3 \t torch.int8\n",
      "224, \t cuda:3 \t torch.float16\n",
      "225, \t cuda:3 \t torch.float16\n",
      "226, \t cuda:3 \t torch.int8\n",
      "227, \t cuda:3 \t torch.int8\n",
      "228, \t cuda:3 \t torch.int8\n",
      "229, \t cuda:3 \t torch.int8\n",
      "230, \t cuda:3 \t torch.int8\n",
      "231, \t cuda:3 \t torch.int8\n",
      "232, \t cuda:3 \t torch.int8\n",
      "233, \t cuda:3 \t torch.float16\n",
      "234, \t cuda:3 \t torch.float16\n",
      "235, \t cuda:3 \t torch.int8\n",
      "236, \t cuda:3 \t torch.int8\n",
      "237, \t cuda:3 \t torch.int8\n",
      "238, \t cuda:3 \t torch.int8\n",
      "239, \t cuda:3 \t torch.int8\n",
      "240, \t cuda:3 \t torch.int8\n",
      "241, \t cuda:3 \t torch.int8\n",
      "242, \t cuda:3 \t torch.float16\n",
      "243, \t cuda:3 \t torch.float16\n",
      "244, \t cuda:3 \t torch.int8\n",
      "245, \t cuda:3 \t torch.int8\n",
      "246, \t cuda:3 \t torch.int8\n",
      "247, \t cuda:3 \t torch.int8\n",
      "248, \t cuda:3 \t torch.int8\n",
      "249, \t cuda:3 \t torch.int8\n",
      "250, \t cuda:3 \t torch.int8\n",
      "251, \t cuda:3 \t torch.float16\n",
      "252, \t cuda:3 \t torch.float16\n",
      "253, \t cuda:3 \t torch.int8\n",
      "254, \t cuda:3 \t torch.int8\n",
      "255, \t cuda:3 \t torch.int8\n",
      "256, \t cuda:3 \t torch.int8\n",
      "257, \t cuda:3 \t torch.int8\n",
      "258, \t cuda:3 \t torch.int8\n",
      "259, \t cuda:3 \t torch.int8\n",
      "260, \t cuda:3 \t torch.float16\n",
      "261, \t cuda:3 \t torch.float16\n",
      "262, \t cuda:3 \t torch.int8\n",
      "263, \t cuda:3 \t torch.int8\n",
      "264, \t cuda:3 \t torch.int8\n",
      "265, \t cuda:3 \t torch.int8\n",
      "266, \t cuda:3 \t torch.int8\n",
      "267, \t cuda:3 \t torch.int8\n",
      "268, \t cuda:3 \t torch.int8\n",
      "269, \t cuda:3 \t torch.float16\n",
      "270, \t cuda:3 \t torch.float16\n",
      "271, \t cuda:3 \t torch.int8\n",
      "272, \t cuda:3 \t torch.int8\n",
      "273, \t cuda:3 \t torch.int8\n",
      "274, \t cuda:3 \t torch.int8\n",
      "275, \t cuda:3 \t torch.int8\n",
      "276, \t cuda:3 \t torch.int8\n",
      "277, \t cuda:3 \t torch.int8\n",
      "278, \t cuda:3 \t torch.float16\n",
      "279, \t cuda:3 \t torch.float16\n",
      "280, \t cuda:3 \t torch.int8\n",
      "281, \t cuda:3 \t torch.int8\n",
      "282, \t cuda:3 \t torch.int8\n",
      "283, \t cuda:3 \t torch.int8\n",
      "284, \t cuda:3 \t torch.int8\n",
      "285, \t cuda:3 \t torch.int8\n",
      "286, \t cuda:3 \t torch.int8\n",
      "287, \t cuda:3 \t torch.float16\n",
      "288, \t cuda:3 \t torch.float16\n",
      "289, \t cuda:3 \t torch.float16\n",
      "290, \t cuda:3 \t torch.float16\n"
     ]
    }
   ],
   "source": [
    "for i, para in enumerate(model.named_parameters()):\n",
    "    print(f\"{i}, \\t {para[1].device} \\t {para[1].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f34f0",
   "metadata": {},
   "source": [
    "# Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af5c7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a1d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.net1 = nn.Linear(10000, 10).to(\"cuda:0\")\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5).to(\"cuda:1\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.net1(x.to(\"cuda:0\")))\n",
    "        return self.net2(x.to(\"cuda:1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "152d5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e58347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a76d836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(model.net1.parameters())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a73ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "print(next(model.net1.parameters())[0].device)\n",
    "print(next(model.net2.parameters())[0].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e73ae57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ToyModel()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "outputs = model(torch.randn(20, 10000))\n",
    "labels = torch.randn(20, 5).to(\"cuda:1\")\n",
    "\n",
    "loss = loss_fn(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4117cb",
   "metadata": {},
   "source": [
    "## Split ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "010c79e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import ResNet, Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b88dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(Bottleneck, [3, 4 ,6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830ed63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3963db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((2, 3, 4))\n",
    "print(t.shape)\n",
    "\n",
    "t.view(t.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "283c0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParallelResNet50(ResNet):\n",
    "    \n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__(Bottleneck, [3,4,6,3], num_classes=num_classes)\n",
    "        \n",
    "        self.seq1 = nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.bn1,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            self.layer1,\n",
    "            self.layer2,\n",
    "        ).to(\"cuda:0\")\n",
    "        \n",
    "        self.seq2 = nn.Sequential(\n",
    "            self.layer3,\n",
    "            self.layer4,\n",
    "            self.avgpool,\n",
    "        ).to(\"cuda:1\")\n",
    "        \n",
    "        self.fc.to('cuda:1')\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.seq1(x).to(\"cuda:1\")\n",
    "        x = self.seq2(x)\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aad1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_size(model):\n",
    "    return sum([para.numel() for para in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95e1378b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de810149",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_model = ModelParallelResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f654a8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6b6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d72d2056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[498],\n",
       "        [627],\n",
       "        [573],\n",
       "        [931],\n",
       "        [443]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_indices = torch.LongTensor(5).random_(0, num_classes).view(5, 1)\n",
    "one_hot_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ef95c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.zeros(5, num_classes).scatter_(1, one_hot_indices, 1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5ed355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 3\n",
    "batch_size = 120\n",
    "image_w = 128\n",
    "image_h = 128\n",
    "\n",
    "def train(model):\n",
    "    model.train(True)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    one_hot_indices = torch.LongTensor(batch_size).random_(0, num_classes).view(batch_size, 1)\n",
    "    \n",
    "    for _ in range(num_batches):\n",
    "        # generate random inputs and labels\n",
    "        # (b, c, w, h)\n",
    "        inputs = torch.randn(batch_size, 3, image_w, image_h).to(\"cuda:0\")\n",
    "        labels = torch.zeros(batch_size, num_classes).scatter_(1, one_hot_indices, 1)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.to(outputs.device)\n",
    "        loss_fn(outputs, labels).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deee4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(mp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66dede50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "num_repeat = 10\n",
    "\n",
    "stmt = \"train(model)\"\n",
    "\n",
    "setup = \"model = ModelParallelResNet50()\"\n",
    "\n",
    "mp_run_time = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals()\n",
    ")\n",
    "\n",
    "mp_mean, mp_std = np.mean(mp_run_time), np.std(mp_run_time)\n",
    "\n",
    "setup = \"import torchvision.models as models;\" + \\\n",
    "        \"model = models.resnet50(num_classes=num_classes).to('cuda:0')\"\n",
    "\n",
    "rn_run_time = timeit.repeat(\n",
    "    stmt, setup, number=1, repeat=num_repeat, globals=globals()\n",
    ")\n",
    "\n",
    "rn_mean, rn_std = np.mean(rn_run_time), np.std(rn_run_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "457a2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(means, stds, labels, fig_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(np.arange(len(means)), means, yerr=stds, align='center', alpha=0.5, ecolor='red', capsize=10, width=0.6)\n",
    "    ax.set_ylabel(\"ResNet50 Execution Time (Second)\")\n",
    "    ax.set_xticks(np.arange(len(means)))\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b352c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([mp_mean, rn_mean], [mp_std, rn_std], ['Model Parallel', 'Single GPU'], 'mp vs rn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-distributed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
